<span id = "Top"> </span>
 [News](#News) | [Publications](#Publications)  | [Services](#Services)| [Students](#Students) | [Resources](#Resources) |
# Peng Song

<p style="width:970px;">
    <img src="/peng.jpg" align="right" width="180" hspace="5" vspace="5">
I received my PhD and M.S. degrees in EE from School of Information Science and Engineering, Southeast University, China in 2014 and 2009, respectively, supervised by Prof. Li Zhao .  Before that, I got my Bachelor's degree in EE from Shandong University of Science and Technology, China in 2006. From 2007 to 2008, I was a research intern at speech group of Microsoft Research Asia. From 2009 to 2011, I worked as a software engineer at Motorola China Software R&D Center. My currewnt research interests include affective computing, speech signal processing, machine Learning, and pattern recognition.
</p>

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

## Basic Inforamtion
**Afflicationï¼š** School of Computer and Control Engineering, Yantai University   
**Titleï¼š**  Associate Professor   
**E-mailï¼š** pengsongseu@gmail.com, pengsong@ytu.edu.cn   
**Officeï¼š** 30, Qingquan RD, Laishan District, Yantai, China

<span id = "News"> </span>
## **News**
* ğŸˆ

<span id = "Publications"> </span>
 ## **Selected Publication:** ï¼ˆ<a href="https://scholar.google.com/citations?user=6zxeFQIAAAAJ&hl=zh-TW">Google Scholar</a>ï¼‰ 
\# Studentsï¼Œ\* Corresponding author

<span style="color:blue;">**Journal Papers**</span>
1. <u>Peng Song*</u>, Wenming Zheng. Feature Selection Based Transfer Subspace Learning for Speech Emotion Recognition. ***IIEEE Transactions on Affective Computing***. 2020, 11(3): 373-382.
2020. Tengfei Song, Wenming Zheng,Â <u>Peng Song</u>, Zhen Cui, EEG Emotion Recognition Using Dynamical Graph Convolutional Neural Networks,Â ***IIEEE Transactions on Affective Computing***. 2020, 11(3): 532-541.
2020. Weijian Zhang #, <u>Peng Song*</u>. Transfer sparse discriminant subspace learning for cross-corpus speech emotion recognition. ***IIEEE/ACM Transactions on Audio, Speech, and Language Processing***. 2020, 28, 307-318.
2020. <u>Peng Song*</u>, Wenming Zheng, Yanwei Yu, Shifeng Ou. Speech Emotion Recognition Based on Robust Discriminative Sparse Regression. ***IIEEE Transactions on Cognitive and Developmental Systems***, 2020 (**In press**) 
2020. Fang Liu#, Yanwei Yu, <u>Peng Song</u>, Yangyang Fan, Xiangrong Tong. Scalable KDE-based Top-n Local Outlier Detection over Large-Scale Data Streams. ***Knowledge-Based Systems***, 2020, 204: 106186ã€‚
2020. Kai Chen#, Yanwei Yu, <u>Peng Song</u>, Xianfeng Tang, Lei Cao, Xiangrong Tong. Find You If You Drive: Inferring Home Locations for Vehicles with Surveillance Camera Data. ***Knowledge-Based Systems***, 2020, 196: 105766ã€‚
2019. <u>Peng Song*</u>. Transfer Linear Subspace Learning for Cross-corpus Speech Emotion Recognition.  ***IEEE Transactions on Affective Computing***. Vol. 10, No. 2, pp. 265-275, 2019.
2018. Shifeng Ou,Â <u>Peng Song</u>, Ying Gao. Laplacian Speech Model and Soft Decision Based MMSE Estimator for Noise Power Spectral Density in Speech Enhancement.***Chinese Journal of Electronics***. 2018,Â  27(6): 1214-1220.
2018. Shifeng Ou,Â <u>Peng Song</u>, Ying Gao. Soft Decision Based Gaussian-Laplacian Combination Model for Noisy Speech Enhancement.Â ***Chinese Journal of Electronics***. 2018,Â  27(4): 827-834.
2017. Shifeng Ou, <u>Peng Song</u>, Ying Gao. Phase-Sensitive Decision-Directed SNR Estimator for Single-Channel Speech Enhancement. ***International Journal of Pattern Recognition and Artificial Intelligence***. 2017, 31(8): 1758003-1~1758003-16. 
2016. <u>Peng Song*</u>, Wenming Zheng, Shifeng Ou, et al. Cross-corpus speech emotion recognition based on transfer non-negative matrix factorization.Â ***Speech Communication***. 2016, 83:34-41. 

<span style="color:blue;">**Conference Papers**</span>
1. Zhijun Liu#, Chao Huang, Yanwei Yu, <u>Peng Song</u>, Baode Fan, Junyu Dong. Dynamic Representation Learning for Large-Scale Attributed Networks. Proceedings of the 29th ACM International Conference on Information and Knowledge Management (**CIKM2020**), October 19--23, 2020, Virtual Event, Ireland, 2020
2020. Jianian Li#, Yanwei Yu, <u>Peng Song</u>, Yunhong Lu. Student Performance Prediction based on Multi-View Network Embedding. 3rd Chinese Conference on Pattern Recognition and Computer Vision (**PRCV2020**). 
2018. <u>Peng Song*</u>, Wenming Zheng, Shifeng Ou, Yun Jin, Wenming Ma, Yanwei Yu. Joint Transfer Subspace Learning and Feature Selection for Cross-corpus Speech Emotion Recognition.  International Conference on Acoustics, Speech and Signal Processing (**ICASSP 2018**), Calgary, Canada, 2018, 5504-5508ã€‚
2016. <u>Peng Song*</u>, Shifeng Ou, Wenming Zheng, et al. Speech Emotion Recognition Using Transfer Non-negative Matrix Factorization. **ICASSP** 2016ï¼ŒShanghai, China, 2016. 
2014. <u>Peng Song*</u>, Yun Jin, Wenming Zheng, et al. Text-independent voice conversion using speaker model alignment method from non-parallel speech. In:Â **INTERSPEECH** 2014,Â  Singapore. 2308-2312, 2014.Â 
2014. Yun Jin,<u>Peng Song*</u>, Wenming Zheng, et al. A feature selection and feature fusion combination method for speaker-independent speech emotion recognition. **ICASSP** 2014. 2014, Florence, Italy. 4841-4845.
2013. <u>Peng Song*</u>, Wenming Zheng, Li Zhao. Non-parallel training for voice conversion based on adaptation method. **ICASSP** 2013. 2013, Vancovour, Canada. 6905-6909.

[*See Peng Songâ€™s Google Scholar for the full publications.*](https://scholar.google.com/citations?user=6zxeFQIAAAAJ&hl=zh-TW)  


<span id = "Services"> </span>
## **Activies**
**Reviewers**ï¼šIEEE Transactions on Affective Computingã€IEEE Signal Processing Lettersã€Speech Communicationã€Neurocomputingã€Information Fusionã€Signal Processingã€Applied Acoustics, etc.

<span id = "Students"> </span>
## **Students**


<span id = "Resources"> </span>
## **Resources**
1. [ä¸­å›½è®¡ç®—æœºå­¦ä¼šæ¨èå›½é™…å­¦æœ¯ä¼šè®®å’ŒæœŸåˆŠç›®å½•](https://www.ccf.org.cn/c/2019-04-25/663625.shtml)
2. [æ¸…åå¤§å­¦è®¡ç®—æœºå­¦ç§‘æ¨èå­¦æœ¯ä¼šè®®å’ŒæœŸåˆŠåˆ—è¡¨](https://dsc.jnu.edu.cn/56/e9/c15581a415465/page.htm)
3. [æœºå™¨å­¦ä¹ ç™½æ¿æ¨å¯¼](https://space.bilibili.com/97068901?from=search&seid=6239692258513089842)
4. [å¸ˆç”Ÿå…³ç³»å¤§æ‚çƒ©](https://frostliu.github.io/discussions)

[â†‘Top](#Top)

<a href="https://info.flagcounter.com/B3Rj"><img src="https://s11.flagcounter.com/map/B3Rj/size_s/txt_000000/border_CCCCCC/pageviews_0/viewers_0/flags_0/" alt="Flag Counter" border="0"></a>

**Updateï¼š2020/09/01**

