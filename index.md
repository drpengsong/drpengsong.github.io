<span id = "Top"> </span>
 [News](#News) | [Publications](#Publications)  | [Services](#Services)| [Students](#Students) | [Resources](#Resources) |
# å®‹é¹ 

<p style="width:970px;">
    <img src="/peng.jpg" align="right" width="180" hspace="5" vspace="5">
ç›®å‰ä¸ºçƒŸå°å¤§å­¦è®¡ç®—æœºä¸æ§åˆ¶å·¥ç¨‹å­¦é™¢å‰¯æ•™æˆã€ç¡•å£«ç”Ÿå¯¼å¸ˆï¼Œåšå£«æ¯•ä¸šäºä¸œå—å¤§å­¦ä¿¡æ¯å­¦é™¢ã€‚ä¸ºIEEE/CCF/CAAå­¦ä¼šä¼šå‘˜ï¼Œå…ˆåä¸»æŒå›½å®¶/çœè‡ªç„¶ç§‘å­¦åŸºé‡‘ã€æ•™è‚²éƒ¨é‡ç‚¹å®éªŒå®¤å¼€æ”¾åŸºé‡‘å¤šé¡¹ã€‚ä¸»è¦ç ”ç©¶æ–¹å‘æ˜¯æƒ…æ„Ÿè®¡ç®—ã€æ¨¡å¼è¯†åˆ«ã€è¯­éŸ³ä¿¡å·å¤„ç†ç­‰ã€‚ç›¸å…³å·¥ä½œå‘è¡¨åœ¨å›½å†…å¤–é‡è¦å­¦æœ¯æœŸåˆŠIEEE TACã€IEEE TASLPã€IEEE TCDSã€Speech CommunicationåŠè¯­éŸ³é¢†åŸŸé‡è¦å›½é™…å­¦æœ¯ä¼šè®®å¦‚ICASSPã€INTERSPEECHç­‰ã€‚
</p>

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

## åŸºæœ¬ä¿¡æ¯
**å·¥ä½œå•ä½ï¼š** çƒŸå°å¤§å­¦è®¡ç®—æœºä¸æ§åˆ¶å·¥ç¨‹å­¦é™¢   
**ç°ä»»èŒç§°ï¼š** å‰¯æ•™æˆ   
**ç”µå­é‚®ç®±ï¼š** pengsongseu@gmail.com, pengsong@ytu.edu.cn   
**åŠå…¬åœ°å€ï¼š** å±±ä¸œçœçƒŸå°å¸‚è±å±±åŒºæ¸…æ³‰è·¯30å·çƒŸå°å¤§å­¦ç»¼åˆæ¥¼633

<span id = "News"> </span>
## **æ–°é—»**
* ğŸˆæ¬¢è¿è®¡ç®—æœºã€ç”µå­ä¿¡æ¯ã€è‡ªåŠ¨åŒ–ç­‰ç›¸å…³ä¸“ä¸šä¼˜ç§€åŒå­¦åŠ ç›Ÿè¯¾é¢˜ç»„ï¼

<span id = "Publications"> </span>
## **éƒ¨åˆ†è®ºæ–‡:** ï¼ˆ<a href="https://scholar.google.com/citations?user=6zxeFQIAAAAJ&hl=zh-TW">è°·æ­Œå­¦æœ¯</a>ï¼‰ 
\# å­¦ç”Ÿï¼Œ\* é€šè®¯ä½œè€…

<span style="color:blue;">**æœŸåˆŠè®ºæ–‡**</span>
1. <u>Peng Song*</u>, Wenming Zheng. Feature Selection Based Transfer Subspace Learning for Speech Emotion Recognition. IEEE Transactions on Affective Computing. 2020, 11(3): 373-382.
2020. Tengfei Song, Wenming Zheng,Â <u>Peng Song</u>, Zhen Cui, EEG Emotion Recognition Using Dynamical Graph Convolutional Neural Networks,Â IEEE Transactions on Affective Computing. 2020, 11(3): 532-541.
2020. Weijian Zhang #, <u>Peng Song*</u>. Transfer sparse discriminant subspace learning for cross-corpus speech emotion recognition. IEEE/ACM Transactions on Audio, Speech, and Language Processing. 2020, 28, 307-318.
2020. <u>Peng Song*</u>, Wenming Zheng, Yanwei Yu, Shifeng Ou. Speech Emotion Recognition Based on Robust Discriminative Sparse Regression. IEEE Transactions on Cognitive and Developmental Systems, 2020 (**In press**) 
2020. Fang Liu#, Yanwei Yu, <u>Peng Song</u>, Yangyang Fan, Xiangrong Tong. Scalable KDE-based Top-n Local Outlier Detection over Large-Scale Data Streams. Knowledge-Based Systems, 2020, 204: 106186ã€‚
2020. Kai Chen#, Yanwei Yu, <u>Peng Song</u>, Xianfeng Tang, Lei Cao, Xiangrong Tong. Find You If You Drive: Inferring Home Locations for Vehicles with Surveillance Camera Data. Knowledge-Based Systems, 2020, 196: 105766ã€‚
2019. <u>Peng Song*</u>. Transfer Linear Subspace Learning for Cross-corpus Speech Emotion Recognition.  IEEE Transactions on Affective Computing. Vol. 10, No. 2, pp. 265-275, 2019.
2018. Shifeng Ou,Â <u>Peng Song</u>, Ying Gao. Laplacian Speech Model and Soft Decision Based MMSE Estimator for Noise Power Spectral Density in Speech Enhancement. Chinese Journal of Electronics. 2018,Â  27(6): 1214-1220.
2018. Shifeng Ou,Â <u>Peng Song</u>, Ying Gao. Soft Decision Based Gaussian-Laplacian Combination Model for Noisy Speech Enhancement.Â Chinese Journal of Electronics. 2018,Â  27(4): 827-834.
2017. Shifeng Ou, <u>Peng Song</u>, Ying Gao. Phase-Sensitive Decision-Directed SNR Estimator for Single-Channel Speech Enhancement.International Journal of Pattern Recognition and Artificial Intelligence. 2017, 31(8): 1758003-1~1758003-16. 
2016. <u>Peng Song*</u>, Wenming Zheng, Shifeng Ou, et al. Cross-corpus speech emotion recognition based on transfer non-negative matrix factorization.Â Speech Communication. 2016, 83:34-41. 
2018. <u>å®‹é¹</u>, éƒ‘æ–‡æ˜, èµµåŠ›. åŸºäºå­ç©ºé—´å­¦ä¹ å’Œç‰¹å¾é€‰æ‹©èåˆçš„è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«.Â Â æ¸…åå¤§å­¦å­¦æŠ¥ï¼ˆè‡ªç„¶ç§‘å­¦ç‰ˆ). 2018, 58(4):347-351.
2016. <u>å®‹é¹</u>, éƒ‘æ–‡æ˜, èµµåŠ›. åŸºäºç‰¹å¾è¿ç§»å­¦ä¹ æ–¹æ³•çš„è·¨åº“è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«, æ¸…åå¤§å­¦å­¦æŠ¥(è‡ªç„¶ç§‘å­¦ç‰ˆ),  2016, 56 (11): 1179-1183.
2015. é‡‘èµŸ,Â <u>å®‹é¹</u>,Â éƒ‘æ–‡æ˜,Â èµµåŠ›.Â åŠç›‘ç£åˆ¤åˆ«åˆ†æçš„è·¨åº“è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«.Â å£°å­¦å­¦æŠ¥, 2015, 40(1): 20-27. 
2013. <u>å®‹é¹</u>ï¼Œç‹æµ©ï¼ŒèµµåŠ›. åŸºäºæ··åˆGausså½’ä¸€åŒ–çš„è¯­éŸ³è½¬æ¢ç®—æ³•[J],Â æ¸…åå¤§å­¦å­¦æŠ¥ï¼ˆè‡ªç„¶ç§‘å­¦ç‰ˆï¼‰,Â 2013, 53(6):757-761. 

<span style="color:blue;">**ä¼šè®®è®ºæ–‡**</span>
1. Zhijun Liu#, Chao Huang, Yanwei Yu, <u>Peng Song</u>, Baode Fan, Junyu Dong. Dynamic Representation Learning for Large-Scale Attributed Networks. Proceedings of the 29th ACM International Conference on Information and Knowledge Management (**CIKM2020**), October 19--23, 2020, Virtual Event, Ireland, 2020
2020. Jianian Li#, Yanwei Yu, <u>Peng Song</u>, Yunhong Lu. Student Performance Prediction based on Multi-View Network Embedding. 3rd Chinese Conference on Pattern Recognition and Computer Vision (**PRCV2020**). 
2018. <u>Peng Song*</u>, Wenming Zheng, Shifeng Ou, Yun Jin, Wenming Ma, Yanwei Yu. Joint Transfer Subspace Learning and Feature Selection for Cross-corpus Speech Emotion Recognition.  International Conference on Acoustics, Speech and Signal Processing (ICASSP 2018), Calgary, Canada, 2018, 5504-5508ã€‚
2016. <u>Peng Song*</u>, Shifeng Ou, Wenming Zheng, et al. Speech Emotion Recognition Using Transfer Non-negative Matrix Factorization. ICASSP 2016ï¼ŒShanghai, China, 2016. 
2014. <u>Peng Song*</u>, Yun Jin, Wenming Zheng, et al. Text-independent voice conversion using speaker model alignment method from non-parallel speech. In:Â INTERSPEECH 2014,Â  Singapore. 2308-2312, 2014.Â 
2014. Yun Jin,<u>Peng Song*</u>, Wenming Zheng, et al. A feature selection and feature fusion combination method for speaker-independent speech emotion recognition. ICASSP 2014. 2014, Florence, Italy. 4841-4845.
2013. <u>Peng Song*</u>, Wenming Zheng, Li Zhao. Non-parallel training for voice conversion based on adaptation method. ICASSP 2013. 2013, Vancovour, Canada. 6905-6909.

[*See Peng Songâ€™s Google Scholar for the full publications.*](https://scholar.google.com/citations?user=6zxeFQIAAAAJ&hl=zh-TW)  


<span id = "Services"> </span>
## **ç¤¾ä¼šæ´»åŠ¨**
ç›®å‰æ‹…ä»»ä»¥ä¸‹æœŸåˆŠçš„å®¡ç¨¿äººï¼šIEEE Transactions on Affective Computingã€IEEE Signal Processing Lettersã€Speech Communicationã€Neurocomputingã€Information Fusionã€Signal Processingã€Applied Acousticsç­‰ã€‚

<span id = "Students"> </span>
## **å­¦ç”Ÿ**
2020çº§

2019çº§
1. [å¼ é›¯å©§]()ï¼Œè¿ç§»å­¦ä¹ 
2. [ç››è¶…]()ï¼Œç‰¹å¾é€‰æ‹©

2018çº§
1. [é™ˆæ ‹æ¢]()ï¼Œç ”ç©¶æ–¹å‘ï¼šäººè„¸è¡¨æƒ…è¯†åˆ«ã€è¿ç§»å­¦ä¹ 
2. [å¼ ä¼Ÿå»º]()ï¼Œç ”ç©¶æ–¹å‘ï¼šè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ã€è¿ç§»å­¦ä¹ 

<span id = "Resources"> </span>
## **èµ„æº**
1. [ä¸­å›½è®¡ç®—æœºå­¦ä¼šæ¨èå›½é™…å­¦æœ¯ä¼šè®®å’ŒæœŸåˆŠç›®å½•](https://www.ccf.org.cn/c/2019-04-25/663625.shtml)
2. [æ¸…åå¤§å­¦è®¡ç®—æœºå­¦ç§‘æ¨èå­¦æœ¯ä¼šè®®å’ŒæœŸåˆŠåˆ—è¡¨](https://dsc.jnu.edu.cn/56/e9/c15581a415465/page.htm)
3. [æœºå™¨å­¦ä¹ ç™½æ¿æ¨å¯¼](https://space.bilibili.com/97068901?from=search&seid=6239692258513089842)
4. [å¸ˆç”Ÿå…³ç³»å¤§æ‚çƒ©](https://frostliu.github.io/discussions)

[â†‘Top](#Top)

**æ›´æ–°æ—¶é—´ï¼š2020/08/31**
