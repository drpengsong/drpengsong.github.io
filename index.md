 <span id = "Top"> </span>
 [News](#News) | [Publications](#Publications)  | [Services](#Services)| [Students](#Students) | [Resources](#Resources) |
# å®‹é¹ (<a href="/index-en.html">Peng Song</a>)  

***"Theory without Practice is empty; but Practice without Theory is blind" - Immanuel Kant***    
***"Each problem that I solved became a rule which served afterwards to solve other problems" - Rene Descartes***   

<p style="width:970px;">
    <img src="/peng.jpg" align="right" width="180" hspace="5" vspace="5">
ç›®å‰ä¸ºçƒŸå°å¤§å­¦è®¡ç®—æœºä¸æ§åˆ¶å·¥ç¨‹å­¦é™¢å‰¯æ•™æˆã€ç¡•å£«ç”Ÿå¯¼å¸ˆï¼Œåšå£«æ¯•ä¸šäºä¸œå—å¤§å­¦ä¿¡æ¯å­¦é™¢ï¼Œå…ˆååœ¨å¾®è½¯äºšæ´²ç ”ç©¶é™¢ã€æ‘©æ‰˜ç½—æ‹‰ç­‰å…¬å¸å®ä¹ åŠå·¥ä½œã€‚ç°ä¸ºIEEE/IEICE/ä¸­å›½è®¡ç®—æœºå­¦ä¼š/ä¸­å›½äººå·¥æ™ºèƒ½å­¦ä¼šä¼šå‘˜ï¼Œå…ˆåä¸»æŒå›½å®¶/çœè‡ªç„¶ç§‘å­¦åŸºé‡‘ã€æ•™è‚²éƒ¨é‡ç‚¹å®éªŒå®¤å¼€æ”¾åŸºé‡‘å¤šé¡¹ã€‚ç›¸å…³å·¥ä½œå‘è¡¨åœ¨å›½å†…å¤–é‡è¦å­¦æœ¯æœŸåˆŠï¼ŒåŒ…æ‹¬IEEE Transæ±‡åˆŠï¼ˆTACã€TASLPã€TCDSï¼‰ã€Speech Communicationã€Knowledge-Based Systemsã€Digital Signal Procesingã€ç”µå­å­¦æŠ¥ã€å£°å­¦å­¦æŠ¥åŠè¯­éŸ³é¢†åŸŸé‡è¦å›½é™…å­¦æœ¯ä¼šè®®å¦‚ICASSPã€INTERSPEECHç­‰ã€‚ç›®å‰ä¸»è¦ç ”ç©¶å…´è¶£åŒ…æ‹¬***æƒ…æ„Ÿè®¡ç®—ã€æ¨¡å¼è¯†åˆ«ã€è¯­éŸ³ä¿¡å·å¤„ç†ã€æœºå™¨å­¦ä¹ ***ç­‰ã€‚
</p>

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

## åŸºæœ¬ä¿¡æ¯
**å·¥ä½œå•ä½ï¼š** çƒŸå°å¤§å­¦è®¡ç®—æœºä¸æ§åˆ¶å·¥ç¨‹å­¦é™¢   
**ç”µå­é‚®ç®±ï¼š** pengsongseu@gmail.com  
**åŠå…¬åœ°å€ï¼š** å±±ä¸œçœçƒŸå°å¸‚è±å±±åŒºæ¸…æ³‰è·¯30å·çƒŸå°å¤§å­¦ç»¼åˆæ¥¼633

<span id = "News"> </span>
## **æ–°é—»**
* <span style="color:red;">ğŸˆğŸˆğŸˆ***æ¬¢è¿å„ä½åŒå­¦åŠ ç›Ÿè¯¾é¢˜ç»„æ”»è¯»ç¡•å£«ç ”ç©¶ç”Ÿï¼åŒæ—¶æ¬¢è¿æœ¬ç§‘ç”Ÿè¿›å…¥å®éªŒå®¤ï¼æ¬¢è¿æ„Ÿå…´è¶£çš„åŒå­¦ä¸æˆ‘è”ç³»ã€‚***</span>
* *10/16/2021* ç¥è´ºæˆ‘ä»¬çš„è®ºæ–‡â€œåŸºäºè¿ç§»å›å½’çš„è·¨åŸŸè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«â€å…¥é€‰NCMMSC 2021ä¼˜ç§€è®ºæ–‡å€™é€‰ï¼
* *10/11/2021* ç¥è´ºå®‹ç´«æµ©åŒå­¦çš„è®ºæ–‡"A Novel Discriminative Virtual Label Regression Method for Unsupervised Feature Selection"è¢«IEICE TRANSACTIONS on Information and Systemså½•ç”¨ï¼
* *10/04/2021* ç¥è´ºå¼ é›¯å©§åŒå­¦çš„è®ºæ–‡"A Novel Transferable Sparse Regression Method for Cross-database Facial Expression Recognition"è¢«IEICE TRANSACTIONS on Information and Systemså½•ç”¨ï¼
* *09/08/2021* ç¥è´ºè®ºæ–‡[â€œEmotion Recognition Using Dynamical Graph Convolutional Neural Networksâ€](https://ieeexplore.ieee.org/document/8621147)å…¥é€‰IEEE Transactions on Affective Computingæœ€ä½³è®ºæ–‡ï¼
* *08/23/2021* ç¥è´ºå¼ é›¯å©§åŒå­¦çš„å·¥ä½œâ€œåŸºäºé²æ£’è¿ç§»å­¦ä¹ çš„äººè„¸è¡¨æƒ…è¯†åˆ«ç ”ç©¶â€è£è·çƒŸå°å¤§å­¦ç ”ç©¶ç”Ÿä¼˜ç§€æˆæœå¥–ï¼
* *08/11/2021* ç¥è´ºæç»å‡¯åŒå­¦çš„è®ºæ–‡â€œåŸºäºè¿ç§»å›å½’çš„è·¨åŸŸè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«â€è¢«NCMMSC 2021å½•ç”¨ï¼
* *07/20/2021* ç¥è´ºç››è¶…åŒå­¦çš„è®ºæ–‡["Dual-graph Regularized  Subspace Learning Based  Feature Selection"](https://www.sciencedirect.com/science/article/pii/S1051200421002141)è¢«Digital Signal Processingå½•ç”¨ï¼
* *07/03/2021* ç¥è´ºèµµå¯å¯åŒå­¦çš„è®ºæ–‡[â€œCross-corpus Speech Emotion Recognition Based on Sparse Subspace Transfer Learningâ€](https://link.springer.com/chapter/10.1007/978-3-030-86608-2_51)è¢«CCBR 2021å½•ç”¨ï¼
* *06/10/2021* ç¥è´ºå¼ é›¯å©§åŒå­¦è·å¾—[çƒŸå°å¤§å­¦2021å¹´ç ”ç©¶ç”Ÿç§‘æŠ€åˆ›æ–°åŸºé‡‘é¡¹ç›®ç«‹é¡¹ï¼](https://yjs.ytu.edu.cn/info/1021/2452.htm)
* *06/08/2021* ç¥è´ºè¯¾é¢˜ç»„â€œåŸºäºè¿ç§»å­¦ä¹ çš„è·¨åŸŸäººè„¸è¡¨æƒ…è¯†åˆ«â€é¡¹ç›®è·å¾—å„¿ç«¥å‘å±•ä¸å­¦ä¹ ç§‘å­¦æ•™è‚²éƒ¨é‡ç‚¹å®éªŒå®¤å¼€æ”¾åŸºé‡‘æ”¯æŒï¼
* *06/02/2021* ç¥è´ºåˆ˜å¿—éªã€é™ˆæ ‹æ¢åŒå­¦åˆ†åˆ«è·å¾—å±±ä¸œçœåŠçƒŸå°å¤§å­¦ä¼˜ç§€æ¯•ä¸šç”Ÿï¼
* *05/28/2021* ç¥è´ºå¼ é›¯å©§åŒå­¦çš„è®ºæ–‡["Latent Sparse Transfer Subspace Learning for  Cross-Corpus Facial Expression Recognition"](https://www.sciencedirect.com/science/article/abs/pii/S1051200421001603)è¢«Digital Signal Processingå½•ç”¨ï¼
* *05/01/2021* ç¥è´ºé™ˆæ ‹æ¢åŒå­¦çš„è®ºæ–‡["Learning Transferable Sparse Representations for Cross-corpus Facial Expression Recognition"](https://ieeexplore.ieee.org/document/9423630)è¢«IEEE Transactions on Affective Computingå½•ç”¨ï¼
* *04/28/2021* ç¥è´ºé™ˆæ ‹æ¢åŒå­¦è€ƒå–åå—ç†å·¥å¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ä¸“ä¸šå­¦æœ¯åšå£«ï¼
* *04/22/2021* ç¥è´ºç››è¶…åŒå­¦çš„å·¥ä½œâ€œåŸºäºå­ç©ºé—´å­¦ä¹ å’Œä¼ªæ ‡ç­¾å›å½’çš„æ— ç›‘ç£ç‰¹å¾é€‰æ‹©â€è¢«ã€Šä¿¡å·å¤„ç†ã€‹å½•ç”¨!
* *04/09/2021* ç¥è´ºæˆ‘ä»¬çš„å·¥ä½œâ€œè·¨è¯­ç§è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ç ”ç©¶â€è£è·çƒŸå°å¤§å­¦2021å¹´ä¼˜ç§€ç§‘ç ”æˆæœå¥–äºŒç­‰å¥–!
* *01/24/2021* ç¥è´ºå¼ ä¼Ÿå»ºåŒå­¦çš„è®ºæ–‡[â€œCross-corpus Speech Emotion Recognition Based on Joint Transfer Subspace Learning and Regressionâ€œ](https://ieeexplore.ieee.org/document/9340391/)è¢«IEEE Transactions on Cognitive and Developmental Systemså½•ç”¨ï¼

[**æ›´å¤šæ–°é—»...**](/pastnews)

<span id = "Publications"> </span>
## **å­¦æœ¯è®ºæ–‡:** ï¼ˆ<a href="https://scholar.google.com/citations?user=6zxeFQIAAAAJ&hl=zh-TW">è°·æ­Œå­¦æœ¯</a>ï¼‰ 
\# å­¦ç”Ÿï¼Œ\* é€šè®¯ä½œè€…

<span style="color:blue;">**æœŸåˆŠè®ºæ–‡**</span>
1. Dongliang Chen#, <u>Peng Song*</u>, Wenming Zheng. [Learning Transferable Sparse Representations for Cross-corpus Facial Expression Recognition](https://ieeexplore.ieee.org/document/9423630). ***IEEE Transactions on Affective Computing***. 2021, Doi:10.1109/TAFFC.2021.3077489
2. Weijian Zhang#, <u>Peng Song*</u>, Dongliang Chen, Chao Sheng, Wenjing Zhang. [Cross-corpus Speech Emotion Recognition Based on Joint Transfer Subspace Learning and Regression](https://ieeexplore.ieee.org/document/9340391/). ***IEEE Transactions on Cognitive and Developmental Systems***. 2021, Doi:10.1109/TCDS.2021.3055524
4. <u>Peng Song*</u>, Wenming Zheng, Yanwei Yu, Shifeng Ou. Speech Emotion Recognition Based on Robust Discriminative Sparse Regression. ***IEEE Transactions on Cognitive and Developmental Systems***, 2021, 2, 343-353.
2028.  Chao Sheng#,  <u>Peng Song*</u>,  Weijian Zhang, Dongliang Chen. [Dual-graph Regularized  Subspace Learning Based  Feature Selection](https://www.sciencedirect.com/science/article/abs/pii/S1051200421002141). ***Digital Signal Processing*** 2021, 117:103175. 
2029.  Wenjing Zhang#, <u>Peng Song*</u>, Dongliang Chen, Weijian Zhang. [Latent Sparse Transfer Subspace Learning for  Cross-Corpus Facial Expression Recognition](https://www.sciencedirect.com/science/article/pii/S1051200421001603). ***Digital Signal Processing*** 2021, 116:103121.
2030.  Dongliang Chen#, <u>Peng Song*</u>. [Dual-Graph Regularized Discriminative Transfer Sparse Coding for Facial Expression Recognition](https://reader.elsevier.com/reader/sd/pii/S1051200420302517?token=E4F4114F27BC1B106D358850CAEBE3B66BA3D8BDBCE921A09E0BA4B6F1DF555F5B0052655DCFE3542684697252025B96). ***Digital Singal Processing*** 2021, 108, 102906.
2031. Wenjing Zhang#, <u>Peng Song*</u>, Wenming Zheng. A Novel Transferable Sparse Regression Method for Cross-database Facial Expression Recognition. ***IEICE TRANSACTIONS on Information and Systems***, 2021 (å½•ç”¨,2022å¹´ç¬¬1æœŸå‡ºç‰ˆ)
2032. Zihao Song#, <u>Peng Song*</u>, Chao Sheng, Wenming Zheng, Wenjing Zhang, Shaokai Li. A Novel Discriminative Virtual Label Regression Method for Unsupervised Feature Selection. ***IEICE TRANSACTIONS on Information and Systems***, 2021 (å½•ç”¨ï¼Œ2022å¹´ç¬¬1æœŸå‡ºç‰ˆ)
2033. <u>Peng Song*</u>, Wenming Zheng. Feature Selection Based Transfer Subspace Learning for Speech Emotion Recognition. ***IEEE Transactions on Affective Computing***. 2020, 11(3): 373-382.
2034. Tengfei Song, Wenming Zheng, <u>Peng Song</u>, Zhen Cui, EEG Emotion Recognition Using Dynamical Graph Convolutional Neural Networks, ***IEEE Transactions on Affective Computing***. 2020, 11(3): 532-541. ï¼ˆ**ESIé«˜è¢«å¼•**ï¼‰
2035. Weijian Zhang#, <u>Peng Song*</u>. Transfer sparse discriminant subspace learning for cross-corpus speech emotion recognition. ***IEEE/ACM Transactions on Audio, Speech, and Language Processing***. 2020, 28, 307-318.
2036. Fang Liu#, Yanwei Yu, <u>Peng Song</u>, Yangyang Fan, Xiangrong Tong. Scalable KDE-based Top-n Local Outlier Detection over Large-Scale Data Streams. ***Knowledge-Based Systems***, 2020, 204: 106186.
2037. Kai Chen#, Yanwei Yu, <u>Peng Song</u>, Xianfeng Tang, Lei Cao, Xiangrong Tong. Find You If You Drive: Inferring Home Locations for Vehicles with Surveillance Camera Data. ***Knowledge-Based Systems***, 2020, 196: 105766.
2038. Dongliang Chen#, <u>Peng Song*</u>, Wenjing Zhang, Weijian Zhang, Bingui Xu, Xuan Zhou. Robust Transferable Subspace Learning for Cross-Corpus Facial Expression Recognition. ***IEICE TRANSACTIONS on Information and Systems***, 2020, E-103D: 2241-2245. 
2039. <u>Peng Song*</u>. Transfer Linear Subspace Learning for Cross-corpus Speech Emotion Recognition.  ***IEEE Transactions on Affective Computing***. Vol. 10, No. 2, pp. 265-275, 2019.
2040. Shifeng Ou,Â <u>Peng Song</u>, Ying Gao. Laplacian Speech Model and Soft Decision Based MMSE Estimator for Noise Power Spectral Density in Speech Enhancement.***Chinese Journal of Electronics***. 2018,Â  27(6): 1214-1220.
2041. Shifeng Ou,Â <u>Peng Song</u>, Ying Gao. Soft Decision Based Gaussian-Laplacian Combination Model for Noisy Speech Enhancement.Â ***Chinese Journal of Electronics***. 2018,Â  27(4): 827-834.
2042. Shifeng Ou, <u>Peng Song</u>, Ying Gao. Phase-Sensitive Decision-Directed SNR Estimator for Single-Channel Speech Enhancement. ***International Journal of Pattern Recognition and Artificial Intelligence***. 2017, 31(8): 1758003-1~1758003-16. 
2043. <u>Peng Song*</u>, Wenming Zheng, Shifeng Ou, et al. Cross-corpus speech emotion recognition based on transfer non-negative matrix factorization.Â ***Speech Communication***. 2016, 83:34-41. 
2044. ç››è¶…#, <u>å®‹é¹*</u>, éƒ‘æ–‡æ˜, èµµåŠ›. [åŸºäºå­ç©ºé—´å­¦ä¹ å’Œä¼ªæ ‡ç­¾å›å½’çš„æ— ç›‘ç£ç‰¹å¾é€‰æ‹©](https://scjg.cnki.net/kcms/detail/detail.aspx?filename=XXCN20210528001&dbcode=CJFQ&dbname=CAPJ2021&v=). **ä¿¡å·å¤„ç†**. 2021, 37 (9): 1701-1708.
2045. å¼ é›¯å©§#, <u>å®‹é¹*</u>, é™ˆæ ‹æ¢, éƒ‘æ–‡æ˜, èµµåŠ›. [åŸºäºç¨€ç–å­ç©ºé—´è¿ç§»å­¦ä¹ çš„è·¨åŸŸäººè„¸è¡¨æƒ…è¯†åˆ«](https://sjcj.nuaa.edu.cn/ch/reader/create_pdf.aspx?file_no=202101011&flag=1&journal_id=sjcjycl&year_id=2021). **æ•°æ®é‡‡é›†ä¸å¤„ç†**. 2021, 36(1):113-121.
2046. æ¬§ä¸–å³°, èµµè‰³ç£Š, <u>å®‹é¹</u>,  é«˜é¢–. åŸºäºæ¦‚ç‡è€¦åˆçš„åŒç›´æ¥åˆ¤å†³å…ˆéªŒä¿¡å™ªæ¯”ä¼°è®¡ç®—æ³•. **ç”µå­å­¦æŠ¥**. 2020, 48(8), 1605-1614.
2047. <u>å®‹é¹</u>, éƒ‘æ–‡æ˜, èµµåŠ›. åŸºäºå­ç©ºé—´å­¦ä¹ å’Œç‰¹å¾é€‰æ‹©èåˆçš„è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«.Â Â **æ¸…åå¤§å­¦å­¦æŠ¥ï¼ˆè‡ªç„¶ç§‘å­¦ç‰ˆ)**. 2018, 58(4):347-351.
2048. <u>å®‹é¹</u>, éƒ‘æ–‡æ˜, èµµåŠ›. åŸºäºç‰¹å¾è¿ç§»å­¦ä¹ æ–¹æ³•çš„è·¨åº“è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«, **æ¸…åå¤§å­¦å­¦æŠ¥(è‡ªç„¶ç§‘å­¦ç‰ˆ)**,  2016, 56 (11): 1179-1183.
2049. é‡‘èµŸ,Â <u>å®‹é¹</u>,Â éƒ‘æ–‡æ˜,Â èµµåŠ›.Â åŠç›‘ç£åˆ¤åˆ«åˆ†æçš„è·¨åº“è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«.Â **å£°å­¦å­¦æŠ¥**, 2015, 40(1): 20-27. 
2050. <u>å®‹é¹</u>ï¼Œç‹æµ©ï¼ŒèµµåŠ›. åŸºäºæ··åˆGausså½’ä¸€åŒ–çš„è¯­éŸ³è½¬æ¢ç®—æ³•,Â **æ¸…åå¤§å­¦å­¦æŠ¥ï¼ˆè‡ªç„¶ç§‘å­¦ç‰ˆï¼‰**,Â 2013, 53(6):757-761. 

<span style="color:blue;">**ä¼šè®®è®ºæ–‡**</span>
1. æç»å‡¯#, <u>å®‹é¹*</u>, å¼ é›¯å©§, éƒ‘æ–‡æ˜, èµµåŠ›. åŸºäºè¿ç§»å›å½’çš„è·¨åŸŸè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«. å…¨å›½äººæœºè¯­éŸ³é€šè®¯å­¦æœ¯ä¼šè®® (**NCMMSC2021**), å¾å·, ä¸­å›½. ï¼ˆæœ€ä½³è®ºæ–‡æåï¼‰
2. Keke  Zhao#, <u>Peng Song*</u>, Wenjing Zhang, Weijian Zhang, Shaokai Li, Dongliang Chen, Wenming Zheng. Cross-corpus Speech Emotion Recognition Based on Sparse Subspace Transfer Learning. Chinese Conference on Biometrics Recognition (**CCBR2021**), Shanghai, China, 2021, 466â€“473.
2021. Zhijun Liu#, Chao Huang, Yanwei Yu, <u>Peng Song</u>, Baode Fan, Junyu Dong. Dynamic Representation Learning for Large-Scale Attributed Networks. Proceedings of the 29th ACM International Conference on Information and Knowledge Management (**CIKM2020**), October 19--23, 2020, Virtual Event, Ireland, 2020
2020. Jianian Li#, Yanwei Yu, <u>Peng Song</u>, Yunhong Lu. Student Performance Prediction based on Multi-View Network Embedding. 3rd Chinese Conference on Pattern Recognition and Computer Vision (**PRCV2020**). 
2018. <u>Peng Song*</u>, Wenming Zheng, Shifeng Ou, Yun Jin, Wenming Ma, Yanwei Yu. Joint Transfer Subspace Learning and Feature Selection for Cross-corpus Speech Emotion Recognition.  International Conference on Acoustics, Speech and Signal Processing (**ICASSP 2018**), Calgary, Canada, 2018, 5504-5508ã€‚
2016. <u>Peng Song*</u>, Shifeng Ou, Wenming Zheng, et al. Speech Emotion Recognition Using Transfer Non-negative Matrix Factorization. **ICASSP** 2016ï¼ŒShanghai, China, 2016. 
2014. <u>Peng Song*</u>, Yun Jin, Wenming Zheng, et al. Text-independent voice conversion using speaker model alignment method from non-parallel speech. In:Â **INTERSPEECH** 2014,Â  Singapore. 2308-2312, 2014.Â 
2014. Yun Jin,<u>Peng Song*</u>, Wenming Zheng, et al. A feature selection and feature fusion combination method for speaker-independent speech emotion recognition. **ICASSP** 2014. 2014, Florence, Italy. 4841-4845.
2013. <u>Peng Song*</u>, Wenming Zheng, Li Zhao. Non-parallel training for voice conversion based on adaptation method. **ICASSP** 2013. 2013, Vancovour, Canada. 6905-6909.

[*See Peng Songâ€™s Google Scholar for the full publications.*](https://scholar.google.com/citations?user=6zxeFQIAAAAJ&hl=zh-TW)  


<span id = "Services"> </span>
## **ç¤¾ä¼šæ´»åŠ¨**
ç›®å‰æ‹…ä»»ä»¥ä¸‹æœŸåˆŠæˆ–å›½é™…ä¼šè®®çš„å®¡ç¨¿äººï¼š
* IEEE Transactions on Affective Computing
*  IEEE-ACM Transactions on Audio, Speech and Language Processing
*  IEEE Signal Processing Magazine
*  IEEE Transactions on Knowledge and Data Engineering
*  IEEE Transactions on Circuits and Systems for Video Technology
*  Neural Networks
*  IEEE Multimedia
*  IEEE Signal Processing Letters
*  Speech Communication
*  Information Science
*  Neurocomputing
*  Information Fusion
*  Signal Processing
*  Applied Acoustics
*  Computer Speech&Languange
*  Biomedical Signal Processing and Control
*  INTERSPEECH 2018~2021, ICASSP 2021, NCMMSC 2021
...

<span id = "Students"> </span>
## **æŒ‡å¯¼å­¦ç”Ÿ**
### **ç ”ç©¶ç”Ÿ**
2021çº§
1. [åˆ˜æ¶›]()ï¼Œç ”ç©¶æ–¹å‘ï¼šè¿ç§»å­¦ä¹ ï¼Œäººè„¸è¡¨æƒ…è¯†åˆ«
2. [åˆ˜å…†è™]()ï¼Œç ”ç©¶æ–¹å‘ï¼šå¤šè§†å›¾èšç±»
3. [å‘¨å£«ç’‡]()ï¼Œç ”ç©¶æ–¹å‘ï¼šç‰¹å¾é€‰æ‹©
4. [å§œæ…æ°]()ï¼Œç ”ç©¶æ–¹å‘ï¼šè¿ç§»å­¦ä¹ ï¼Œè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«
5. [ç‰Ÿé‡‘å¸…]()ï¼Œç ”ç©¶æ–¹å‘ï¼šå¤šè§†å›¾èšç±» 
6. [ç‹æ¶¦]()ï¼Œ ç ”ç©¶æ–¹å‘ï¼šè¿ç§»å­¦ä¹ ï¼Œäººè„¸è¡¨æƒ…è¯†åˆ«

2020çº§
1. [èµµå¯å¯]()ï¼Œç ”ç©¶æ–¹å‘ï¼šè·¨åŸŸè¯­éŸ³æƒ…æ„Ÿè¯†åˆ« ï¼ˆCCBR 2021å½•ç”¨è®ºæ–‡ä¸€ç¯‡ï¼‰
2. [å§¬äº®]()ï¼Œç ”ç©¶æ–¹å‘ï¼šè·¨åŸŸäººè„¸è¡¨æƒ…è¯†åˆ« ï¼ˆä¸€ç¯‡è®ºæ–‡åœ¨å®¡ï¼‰
3. [åˆ˜å‘é›¨]()ï¼Œç ”ç©¶æ–¹å‘ï¼šå¤šè§†å›¾èšç±» (ä¸¤ç¯‡è®ºæ–‡åœ¨å®¡)
4. [æç»å‡¯]()ï¼Œç ”ç©¶æ–¹å‘ï¼šè¿ç§»å­¦ä¹ ã€è¯­éŸ³æƒ…æ„Ÿè¯†åˆ« ï¼ˆNCMMSC 2021å½•ç”¨è®ºæ–‡ä¸€ç¯‡ï¼Œä¸€ç¯‡è®ºæ–‡åœ¨å®¡ï¼‰
5. [å®‹ç´«æµ©]()ï¼Œç ”ç©¶æ–¹å‘ï¼šï¼ˆå¤šè§†å›¾ï¼‰ç‰¹å¾é€‰æ‹© (IEICEå½•ç”¨è®ºæ–‡ä¸€ç¯‡)

2019çº§
1. [å¼ é›¯å©§]()ï¼Œç ”ç©¶æ–¹å‘ï¼šåŸºäºè¿ç§»å­¦ä¹ çš„è·¨åŸŸäººè„¸è¡¨æƒ…è¯†åˆ« (DSPã€IEICEã€ã€Šæ•°æ®é‡‡é›†ä¸å¤„ç†ã€‹å„åˆŠå‡ºä¸€ç¯‡ã€ä¸€ç¯‡è®ºæ–‡åœ¨å®¡)
2. [ç››è¶…]()ï¼Œ ç ”ç©¶æ–¹å‘ï¼šåŸºäºå›¾æ­£åˆ™çš„æ— ç›‘ç£ç‰¹å¾é€‰æ‹© (DSPåˆŠå‡ºä¸€ç¯‡ã€ã€Šä¿¡å·å¤„ç†ã€‹å½•ç”¨ä¸€ç¯‡ã€ä¸€ç¯‡è®ºæ–‡åœ¨å®¡)

2018çº§
1. [é™ˆæ ‹æ¢]()ï¼Œç ”ç©¶æ–¹å‘ï¼šåŸºäºç¨€ç–è¿ç§»å­¦ä¹ çš„äººè„¸è¡¨æƒ…è¯†åˆ«. (IEEE TACã€IEICEã€DSPè®ºæ–‡å„åˆŠå‡ºä¸€ç¯‡,ä¸€ç¯‡è®ºæ–‡åœ¨å®¡) **æ¯•ä¸šå»å‘**ï¼šåå—ç†å·¥è¯»åš
2. [å¼ ä¼Ÿå»º]()ï¼Œç ”ç©¶æ–¹å‘ï¼šåŸºäºå­ç©ºé—´è¿ç§»å­¦ä¹ çš„è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«. (IEEE TASLPã€TCDSè®ºæ–‡å„åˆŠå‡ºä¸€ç¯‡) **æ¯•ä¸šå»å‘**ï¼šä¸­å›½ç§»åŠ¨

### **ä¼˜ç§€æœ¬ç§‘æ¯•ä¸šè®ºæ–‡**
1. 2019å¹´ åŸºäºæ·±å±‚å­ç©ºé—´å­¦ä¹ çš„äººè„¸è¡¨æƒ…è¯†åˆ«æ–¹æ³•ç ”ç©¶ å¼ è¿é›ª
2. 2018å¹´ åŸºäºæœºå™¨å­¦ä¹ çš„äº¤é€šå¤§æ•°æ®é¢„æµ‹   æå°šæ³½

### **å¤§å­¦ç”Ÿç§‘æŠ€åˆ›æ–°æ´»åŠ¨**
1. 2021å¹´ ç ”ç©¶ç”Ÿç§‘æŠ€åˆ›æ–°åŸºé‡‘é¡¹ç›®ï¼šåŸºäºè¿ç§»å­¦ä¹ çš„è·¨åŸŸäººè„¸è¡¨æƒ…è¯†åˆ«ç ”ç©¶ï¼ˆå¼ é›¯å©§ï¼‰
2. 2020å¹´ ç ”ç©¶ç”Ÿç§‘æŠ€åˆ›æ–°åŸºé‡‘é¡¹ç›®(é‡ç‚¹)ï¼šåŸºäºå­ç©ºé—´è¿ç§»å­¦ä¹ çš„è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ç ”ç©¶ï¼ˆå¼ ä¼Ÿå»ºï¼‰
3. 2019å¹´ â€œæ™ºæ…§å®éªŒå®¤â€çƒŸå°å¤§å­¦ç¬¬ä¸€å±Šç ”ç©¶ç”Ÿåˆ›æ–°å®è·µå¤§èµ›(ç‰¹ç­‰å¥–)ï¼š è·¨åŒºåŸŸçš„äººè„¸è¡¨æƒ…è¯†åˆ«ï¼ˆé™ˆæ ‹æ¢ã€å¼ é›¯å©§ï¼‰
4. 2017å¹´ å¤§å­¦ç”Ÿåˆ›æ–°åˆ›ä¸šè®­ç»ƒè®¡åˆ’é¡¹ç›®:â€œåŸºäºæœºå™¨å­¦ä¹ çš„åŸå¸‚äº¤é€šåŠ¨æ€é¢„æµ‹â€ ï¼ˆæå€©ã€å¼ è¿é›ªã€é©¬æ–‡é™ã€æå°šæ³½ã€è´¾å¬é£ç­‰ï¼‰
5. 2016-2019å¹´ ä¸–ç•Œå¤§å­¦ç”Ÿè¶…çº§è®¡ç®—æœºæ¯”èµ›ASCï¼ˆäºŒç­‰å¥–ï¼‰

<span id = "Resources"> </span>
## **èµ„æº**
1. [ä¸­å›½è®¡ç®—æœºå­¦ä¼šæ¨èå›½é™…å­¦æœ¯ä¼šè®®å’ŒæœŸåˆŠç›®å½•](https://www.ccf.org.cn/c/2019-04-25/663625.shtml)
2. [æ¸…åå¤§å­¦è®¡ç®—æœºå­¦ç§‘æ¨èå­¦æœ¯ä¼šè®®å’ŒæœŸåˆŠåˆ—è¡¨](http://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf)
3. [ä¸­å›½è‡ªåŠ¨åŒ–å­¦ä¼šæ¨èå­¦æœ¯æœŸåˆŠç›®å½•ï¼ˆè¯•è¡Œï¼‰](http://www.caa.org.cn/Public/FCKuploads/00.pdf)
4. [ä¸­å›½ç§‘æŠ€æœŸåˆŠå“è¶Šè¡ŒåŠ¨è®¡åˆ’å…¥é€‰æœŸåˆŠç›®å½•](https://www.ahjzu.edu.cn/_upload/article/files/9a/d0/ebaa204446199e269bb884015b91/da339269-fd73-40f3-a107-3ca40bfdfe6e.pdf)
5. [æœºå™¨å­¦ä¹ ç™½æ¿æ¨å¯¼](https://space.bilibili.com/97068901?from=search&seid=6239692258513089842)
6. [è¿ç§»å­¦ä¹ ](https://github.com/jindongwang/transferlearning)
7. [è·¨åŸŸäººè„¸è¡¨æƒ…è¯†åˆ«](https://mp.weixin.qq.com/s/vK4jHAntOvwnJ5FwHgDCVw)
8. [å¦‚ä½•åšç ”ç©¶](http://www.jdl.ac.cn/how_to_research/index1_1.htm#1)
9. [å¸ˆç”Ÿå…³ç³»å¤§æ‚çƒ©](https://frostliu.github.io/discussions)
10. [AIä¼šè®®Deadline](https://aideadlin.es/?sub=ML,CV,NLP,RO,SP,DM)


[â†‘Top](#Top)

<a href="https://info.flagcounter.com/B3Rj"><img src="https://s11.flagcounter.com/map/B3Rj/size_s/txt_000000/border_CCCCCC/pageviews_0/viewers_0/flags_0/" alt="Flag Counter" border="0"></a>

**æ›´æ–°æ—¶é—´ï¼š2021/10/28**

