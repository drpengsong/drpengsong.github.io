<span id = "Top"> </span>
 [News](#News) | [Publications](#Publications)  | [Services](#Services)| [Students](#Students) | [Resources](#Resources) |
# å®‹é¹ (<a href="/index-en.html">Peng Song</a>)  

***"Theory without Practice is empty; but Practice without Theory is blind" - Immanuel Kant***    
***"Each problem that I solved became a rule which served afterwards to solve other problems" - Rene Descartes***   

<p style="width:970px;">
    <img src="/peng.jpg" align="right" width="180" hspace="5" vspace="5">
ç›®å‰ä¸ºçƒŸå°å¤§å­¦è®¡ç®—æœºä¸æ§åˆ¶å·¥ç¨‹å­¦é™¢å‰¯æ•™æˆã€ç¡•å£«ç”Ÿå¯¼å¸ˆï¼Œåšå£«æ¯•ä¸šäºä¸œå—å¤§å­¦ä¿¡æ¯å­¦é™¢ï¼Œå…ˆååœ¨å¾®è½¯äºšæ´²ç ”ç©¶é™¢ã€æ‘©æ‰˜ç½—æ‹‰ç­‰å…¬å¸å®ä¹ åŠå·¥ä½œã€‚ç°ä¸ºIEEE/IEICE/ä¸­å›½è®¡ç®—æœºå­¦ä¼š/ä¸­å›½è‡ªåŠ¨åŒ–å­¦ä¼šä¼šå‘˜ï¼Œå…ˆåä¸»æŒå›½å®¶/çœè‡ªç„¶ç§‘å­¦åŸºé‡‘ã€æ•™è‚²éƒ¨é‡ç‚¹å®éªŒå®¤å¼€æ”¾åŸºé‡‘å¤šé¡¹ã€‚ç›¸å…³å·¥ä½œå‘è¡¨åœ¨å›½å†…å¤–é‡è¦å­¦æœ¯æœŸåˆŠï¼ŒåŒ…æ‹¬IEEE Transæ±‡åˆŠï¼ˆTACã€TASLPã€TCDSï¼‰ã€Speech Communicationã€ç”µå­å­¦æŠ¥ã€å£°å­¦å­¦æŠ¥åŠè¯­éŸ³é¢†åŸŸé‡è¦å›½é™…å­¦æœ¯ä¼šè®®å¦‚ICASSPã€INTERSPEECHç­‰ã€‚ç›®å‰ä¸»è¦ç ”ç©¶å…´è¶£åŒ…æ‹¬æƒ…æ„Ÿè®¡ç®—ã€æ¨¡å¼è¯†åˆ«ã€è¯­éŸ³ä¿¡å·å¤„ç†ã€æœºå™¨å­¦ä¹ ç­‰ã€‚
</p>

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

## åŸºæœ¬ä¿¡æ¯
**å·¥ä½œå•ä½ï¼š** çƒŸå°å¤§å­¦è®¡ç®—æœºä¸æ§åˆ¶å·¥ç¨‹å­¦é™¢   
**ç”µå­é‚®ç®±ï¼š** pengsongseu@gmail.com  
**åŠå…¬åœ°å€ï¼š** å±±ä¸œçœçƒŸå°å¸‚è±å±±åŒºæ¸…æ³‰è·¯30å·çƒŸå°å¤§å­¦ç»¼åˆæ¥¼633

<span id = "News"> </span>
## **æ–°é—»**
* <span style="color:red;">***ğŸˆæ¬¢è¿è®¡ç®—æœºã€ç”µå­ä¿¡æ¯ã€æ™ºèƒ½ç§‘å­¦ã€è‡ªåŠ¨åŒ–ç­‰ç›¸å…³ä¸“ä¸šä¼˜ç§€åŒå­¦åŠ ç›Ÿè¯¾é¢˜ç»„æ”»è¯»ç¡•å£«ç ”ç©¶ç”Ÿï¼åŒæ—¶æ¬¢è¿æœ¬ç§‘ç”Ÿè¿›å…¥å®éªŒå®¤ï¼æ¬¢è¿æ„Ÿå…´è¶£çš„åŒå­¦ä¸æˆ‘è”ç³»ã€‚***</span>
* *05/01/2021* ç¥è´ºé™ˆæ ‹æ¢åŒå­¦çš„è®ºæ–‡["Learning Transferable Sparse Representations for Cross-corpus Facial Expression Recognition"](https://ieeexplore.ieee.org/document/9423630)è¢«IEEE Transactions on Affective Computingå½•ç”¨ï¼
* *04/28/2021* ç¥è´ºé™ˆæ ‹æ¢åŒå­¦è€ƒå–åå—ç†å·¥å¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ä¸“ä¸šå­¦æœ¯åšå£«ï¼
* *04/22/2021* ç¥è´ºç››è¶…åŒå­¦çš„å·¥ä½œâ€œåŸºäºå­ç©ºé—´å­¦ä¹ å’Œä¼ªæ ‡ç­¾å›å½’çš„æ— ç›‘ç£ç‰¹å¾é€‰æ‹©â€è¢«ã€Šä¿¡å·å¤„ç†ã€‹å½•ç”¨!
* *04/09/2021* ç¥è´ºæˆ‘ä»¬çš„å·¥ä½œâ€œè·¨è¯­ç§è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ç ”ç©¶â€è£è·çƒŸå°å¤§å­¦2021å¹´ä¼˜ç§€ç§‘ç ”æˆæœå¥–äºŒç­‰å¥–!
* *01/24/2021* ç¥è´ºå¼ ä¼Ÿå»ºåŒå­¦çš„è®ºæ–‡[â€œCross-corpus Speech Emotion Recognition Based on Joint Transfer Subspace Learning and Regressionâ€œ](https://ieeexplore.ieee.org/document/9340391/)è¢«IEEE Transactions on Cognitive and Developmental Systemså½•ç”¨ï¼
* *12/31/2020* ç¥è´ºæˆ‘ä»¬çš„å·¥ä½œ"é¢å‘è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«çš„è¿ç§»å­ç©ºé—´å­¦ä¹ æ–¹æ³•ç ”ç©¶"è£è·[2020å¹´å±±ä¸œçœç ”ç©¶ç”Ÿä¼˜ç§€æˆæœå¥–ä¸‰ç­‰å¥–](http://edu.shandong.gov.cn/art/2020/12/31/art_11990_10285683.html)ï¼
* *12/25/2020* ç¥è´ºå¼ é›¯å©§åŒå­¦çš„è®ºæ–‡[â€œåŸºäºç¨€ç–å­ç©ºé—´è¿ç§»å­¦ä¹ çš„è·¨åŸŸäººè„¸è¡¨æƒ…è¯†åˆ«â€œ](https://sjcj.nuaa.edu.cn/ch/reader/view_abstract.aspx?flag=2&file_no=202011200000001&journal_id=sjcjycl)è¢«ã€Šæ•°æ®é‡‡é›†ä¸å¤„ç†ã€‹å½•ç”¨ï¼
* *11/25/2020* ç¥è´ºæˆ‘ä»¬åœ¨IEEE TACä¸Šçš„è®ºæ–‡[EEG Emotion Recognition Using Dynamical Graph Convolutional Neural Networks](https://ieeexplore.ieee.org/document/8320798)å…¥é€‰ESIé«˜è¢«å¼•è®ºæ–‡ï¼
* *11/25/2020* ç¥è´ºå¼ ä¼Ÿå»ºã€é™ˆæ ‹æ¢ã€åˆ˜å¿—éªåŒå­¦åˆ†åˆ«å…¥é€‰çƒŸå°å¤§å­¦ç ”ç©¶ç”Ÿä¼˜ç§€æˆæœå¥–ä¸€ç­‰å¥–ã€äºŒç­‰å¥–ï¼
* *11/02/2020* ç¥è´ºé™ˆæ ‹æ¢åŒå­¦çš„è®ºæ–‡[Dual-Graph Regularized Discriminative Transfer Sparse Coding for Facial Expression Recognition](https://reader.elsevier.com/reader/sd/pii/S1051200420302517?token=E4F4114F27BC1B106D358850CAEBE3B66BA3D8BDBCE921A09E0BA4B6F1DF555F5B0052655DCFE3542684697252025B96)è¢«Digital Signal Processing (ä¸­ç§‘é™¢åˆ†åŒºSCIäºŒåŒºæœŸåˆŠ) å½•ç”¨ï¼
* *10/22/2020* [ç¥è´ºå¼ ä¼Ÿå»ºåŒå­¦è·ç ”ç©¶ç”Ÿå›½å®¶å¥–å­¦é‡‘ï¼](https://stu.ytu.edu.cn/info/1042/4200.htm)
* *08/01/2020* ç¥è´ºè®ºæ–‡"åŸºäºæ¦‚ç‡è€¦åˆçš„åŒç›´æ¥åˆ¤å†³å…ˆéªŒä¿¡å™ªæ¯”ä¼°è®¡ç®—æ³•"åœ¨ã€Šç”µå­å­¦æŠ¥ã€‹å‘è¡¨ï¼
* *07/17/2020* ç¥è´ºåˆ˜å¿—éªåŒå­¦çš„è®ºæ–‡Dynamic Representation Learning for Large-Scale Attributed Networksè¢«CIKM 2020å½•ç”¨ï¼
* *07/08/2020* ç¥è´ºé™ˆæ ‹æ¢åŒå­¦çš„è®ºæ–‡Robust Transferable Subspace Learning for Cross-Corpus Facial Expression Recognitionè¢«IEICE TRANSACTIONS on Information and Systemså½•ç”¨ï¼
* *06/22/2020* ç¥è´ºåˆ˜èŠ³åŒå­¦çš„è®ºæ–‡Scalable KDE-based Top-n Local Outlier Detection over Large-Scale Data Streamsè¢«Knowledge-based Systemså½•ç”¨ï¼
* *03/09/2020* ç¥è´ºé™ˆå‡¯åŒå­¦çš„è®ºæ–‡Find You If You Drive: Inferring Home Locations for Vehicles with Surveillance Camera Dataè¢«Knowledge-based Systemså½•ç”¨ï¼	
* *04/16/2020* ç¥è´ºå¼ ä¼Ÿå»ºåŒå­¦è·å¾—[çƒŸå°å¤§å­¦2020å¹´ç ”ç©¶ç”Ÿç§‘æŠ€åˆ›æ–°åŸºé‡‘é‡ç‚¹é¡¹ç›®ç«‹é¡¹ï¼](https://yjs.ytu.edu.cn/info/1023/2254.htm)
* *03/18/2020* ç¥è´ºè®ºæ–‡Speech Emotion Recognition Based on Robust Discriminative Sparse Regressionè¢«IEEE Transactions on Cognitive and Developmental Systemså½•ç”¨ï¼


[See more past news.](/pastnews)

<span id = "Publications"> </span>
## **éƒ¨åˆ†è®ºæ–‡:** ï¼ˆ<a href="https://scholar.google.com/citations?user=6zxeFQIAAAAJ&hl=zh-TW">è°·æ­Œå­¦æœ¯</a>ï¼‰ 
\# å­¦ç”Ÿï¼Œ\* é€šè®¯ä½œè€…

<span style="color:blue;">**æœŸåˆŠè®ºæ–‡**</span>
1. Dongliang Chen#, <u>Peng Song*</u>, Wenjing Zhang, Wenming Zheng. Joint Transfer Sparse Coding and Subspace Learning for Cross-corpus Facial Expression Recognition. ***IEEE Transactions on Biometrics, Behavior, and Identity Science*** (Under Review)
2021. Wenjing Zhang#, <u>Peng Song*</u>, Dongliang Chen, Wenjian Zhang. Latent Sparse Transfer Subspace Learning for  Cross-Corpus Facial Expression Recognition. ***Digital Signal Processing*** (Major revision)
2022. Chao Sheng#, <u>Peng Song*</u>,  Wenming Zheng. Graph Regularized  Virtual Label Regression for Unsupervised Feature Selection. ***Knowledge-Based Systems*** (Under review)
2024. Chao Sheng#, <u>Peng Song*</u>,  Weijian Zhang,  Dongliang Chen.  Dual-graph Regularized  Subspace Learning Based  Feature Selection. ***Digital Signal Processing*** (Under review)
2025. Dongliang Chen#, <u>Peng Song*</u>, Wenming Zheng. [Learning Transferable Sparse Representations for Cross-corpus Facial Expression Recognition](https://ieeexplore.ieee.org/document/9423630). ***IEEE Transactions on Affective Computing***. 2021, Doi:10.1109/TAFFC.2021.3077489
2026. Weijian Zhang#, <u>Peng Song*</u>, Dongliang Chen, Chao Sheng, Wenjing Zhang. [Cross-corpus Speech Emotion Recognition Based on Joint Transfer Subspace Learning and Regression](https://ieeexplore.ieee.org/document/9340391/). ***IEEE Transactions on Cognitive and Developmental Systems***. 2021, Doi:10.1109/TCDS.2021.3055524
2027. Dongliang Chen#, <u>Peng Song*</u>. [Dual-Graph Regularized Discriminative Transfer Sparse Coding for Facial Expression Recognition](https://reader.elsevier.com/reader/sd/pii/S1051200420302517?token=E4F4114F27BC1B106D358850CAEBE3B66BA3D8BDBCE921A09E0BA4B6F1DF555F5B0052655DCFE3542684697252025B96). ***Digital Singal Processing*** 2021, 108, 102906.
2028. <u>Peng Song*</u>, Wenming Zheng. Feature Selection Based Transfer Subspace Learning for Speech Emotion Recognition. ***IEEE Transactions on Affective Computing***. 2020, 11(3): 373-382.
2029. Tengfei Song, Wenming Zheng, <u>Peng Song</u>, Zhen Cui, EEG Emotion Recognition Using Dynamical Graph Convolutional Neural Networks, ***IEEE Transactions on Affective Computing***. 2020, 11(3): 532-541. ï¼ˆ**ESIé«˜è¢«å¼•**ï¼‰
2030. Weijian Zhang#, <u>Peng Song*</u>. Transfer sparse discriminant subspace learning for cross-corpus speech emotion recognition. ***IEEE/ACM Transactions on Audio, Speech, and Language Processing***. 2020, 28, 307-318.
2031. <u>Peng Song*</u>, Wenming Zheng, Yanwei Yu, Shifeng Ou. Speech Emotion Recognition Based on Robust Discriminative Sparse Regression. ***IEEE Transactions on Cognitive and Developmental Systems***, 2020, DOI: 10.1109/TCDS.2020.2990928.
2032. Fang Liu#, Yanwei Yu, <u>Peng Song</u>, Yangyang Fan, Xiangrong Tong. Scalable KDE-based Top-n Local Outlier Detection over Large-Scale Data Streams. ***Knowledge-Based Systems***, 2020, 204: 106186.
2033. Kai Chen#, Yanwei Yu, <u>Peng Song</u>, Xianfeng Tang, Lei Cao, Xiangrong Tong. Find You If You Drive: Inferring Home Locations for Vehicles with Surveillance Camera Data. ***Knowledge-Based Systems***, 2020, 196: 105766.
2034. Dongliang Chen#, <u>Peng Song*</u>, Wenjing Zhang, Weijian Zhang, Bingui Xu, Xuan Zhou. Robust Transferable Subspace Learning for Cross-Corpus Facial Expression Recognition. ***IEICE TRANSACTIONS on Information and Systems***, 2020, E-103D: 2241-2245. 
2035. <u>Peng Song*</u>. Transfer Linear Subspace Learning for Cross-corpus Speech Emotion Recognition.  ***IEEE Transactions on Affective Computing***. Vol. 10, No. 2, pp. 265-275, 2019.
2036. Shifeng Ou,Â <u>Peng Song</u>, Ying Gao. Laplacian Speech Model and Soft Decision Based MMSE Estimator for Noise Power Spectral Density in Speech Enhancement.***Chinese Journal of Electronics***. 2018,Â  27(6): 1214-1220.
2037. Shifeng Ou,Â <u>Peng Song</u>, Ying Gao. Soft Decision Based Gaussian-Laplacian Combination Model for Noisy Speech Enhancement.Â ***Chinese Journal of Electronics***. 2018,Â  27(4): 827-834.
2038. Shifeng Ou, <u>Peng Song</u>, Ying Gao. Phase-Sensitive Decision-Directed SNR Estimator for Single-Channel Speech Enhancement. ***International Journal of Pattern Recognition and Artificial Intelligence***. 2017, 31(8): 1758003-1~1758003-16. 
2039. <u>Peng Song*</u>, Wenming Zheng, Shifeng Ou, et al. Cross-corpus speech emotion recognition based on transfer non-negative matrix factorization.Â ***Speech Communication***. 2016, 83:34-41. 
2040. ç››è¶…#, <u>å®‹é¹*</u>, éƒ‘æ–‡æ˜, èµµåŠ›. åŸºäºå­ç©ºé—´å­¦ä¹ å’Œä¼ªæ ‡ç­¾å›å½’çš„æ— ç›‘ç£ç‰¹å¾é€‰æ‹©. **ä¿¡å·å¤„ç†**. ï¼ˆå½•ç”¨ï¼‰
2041. å¼ é›¯å©§#, <u>å®‹é¹*</u>, é™ˆæ ‹æ¢, éƒ‘æ–‡æ˜, èµµåŠ›.  åŸºäºç¨€ç–å­ç©ºé—´è¿ç§»å­¦ä¹ çš„è·¨åŸŸäººè„¸è¡¨æƒ…è¯†åˆ«. **æ•°æ®é‡‡é›†ä¸å¤„ç†**. 2021, 36(1):113-121.
2042. æ¬§ä¸–å³°, èµµè‰³ç£Š, <u>å®‹é¹</u>,  é«˜é¢–. åŸºäºæ¦‚ç‡è€¦åˆçš„åŒç›´æ¥åˆ¤å†³å…ˆéªŒä¿¡å™ªæ¯”ä¼°è®¡ç®—æ³•. **ç”µå­å­¦æŠ¥**. 2020, 48(8), 1605-1614.
2043. <u>å®‹é¹</u>, éƒ‘æ–‡æ˜, èµµåŠ›. åŸºäºå­ç©ºé—´å­¦ä¹ å’Œç‰¹å¾é€‰æ‹©èåˆçš„è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«.Â Â **æ¸…åå¤§å­¦å­¦æŠ¥ï¼ˆè‡ªç„¶ç§‘å­¦ç‰ˆ)**. 2018, 58(4):347-351.
2044. <u>å®‹é¹</u>, éƒ‘æ–‡æ˜, èµµåŠ›. åŸºäºç‰¹å¾è¿ç§»å­¦ä¹ æ–¹æ³•çš„è·¨åº“è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«, **æ¸…åå¤§å­¦å­¦æŠ¥(è‡ªç„¶ç§‘å­¦ç‰ˆ)**,  2016, 56 (11): 1179-1183.
2045. é‡‘èµŸ,Â <u>å®‹é¹</u>,Â éƒ‘æ–‡æ˜,Â èµµåŠ›.Â åŠç›‘ç£åˆ¤åˆ«åˆ†æçš„è·¨åº“è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«.Â **å£°å­¦å­¦æŠ¥**, 2015, 40(1): 20-27. 
2046. <u>å®‹é¹</u>ï¼Œç‹æµ©ï¼ŒèµµåŠ›. åŸºäºæ··åˆGausså½’ä¸€åŒ–çš„è¯­éŸ³è½¬æ¢ç®—æ³•,Â **æ¸…åå¤§å­¦å­¦æŠ¥ï¼ˆè‡ªç„¶ç§‘å­¦ç‰ˆï¼‰**,Â 2013, 53(6):757-761. 

<span style="color:blue;">**ä¼šè®®è®ºæ–‡**</span>
1. Zhijun Liu#, Chao Huang, Yanwei Yu, <u>Peng Song</u>, Baode Fan, Junyu Dong. Dynamic Representation Learning for Large-Scale Attributed Networks. Proceedings of the 29th ACM International Conference on Information and Knowledge Management (**CIKM2020**), October 19--23, 2020, Virtual Event, Ireland, 2020
2020. Jianian Li#, Yanwei Yu, <u>Peng Song</u>, Yunhong Lu. Student Performance Prediction based on Multi-View Network Embedding. 3rd Chinese Conference on Pattern Recognition and Computer Vision (**PRCV2020**). 
2018. <u>Peng Song*</u>, Wenming Zheng, Shifeng Ou, Yun Jin, Wenming Ma, Yanwei Yu. Joint Transfer Subspace Learning and Feature Selection for Cross-corpus Speech Emotion Recognition.  International Conference on Acoustics, Speech and Signal Processing (**ICASSP 2018**), Calgary, Canada, 2018, 5504-5508ã€‚
2016. <u>Peng Song*</u>, Shifeng Ou, Wenming Zheng, et al. Speech Emotion Recognition Using Transfer Non-negative Matrix Factorization. **ICASSP** 2016ï¼ŒShanghai, China, 2016. 
2014. <u>Peng Song*</u>, Yun Jin, Wenming Zheng, et al. Text-independent voice conversion using speaker model alignment method from non-parallel speech. In:Â **INTERSPEECH** 2014,Â  Singapore. 2308-2312, 2014.Â 
2014. Yun Jin,<u>Peng Song*</u>, Wenming Zheng, et al. A feature selection and feature fusion combination method for speaker-independent speech emotion recognition. **ICASSP** 2014. 2014, Florence, Italy. 4841-4845.
2013. <u>Peng Song*</u>, Wenming Zheng, Li Zhao. Non-parallel training for voice conversion based on adaptation method. **ICASSP** 2013. 2013, Vancovour, Canada. 6905-6909.

[*See Peng Songâ€™s Google Scholar for the full publications.*](https://scholar.google.com/citations?user=6zxeFQIAAAAJ&hl=zh-TW)  


<span id = "Services"> </span>
## **ç¤¾ä¼šæ´»åŠ¨**
ç›®å‰æ‹…ä»»ä»¥ä¸‹æœŸåˆŠæˆ–å›½é™…ä¼šè®®çš„å®¡ç¨¿äººï¼š
* IEEE Transactions on Affective Computing
*  IEEE-ACM Transactions on Audio, Speech and Language Processing
*  IEEE Signal Processing Magazine
*  IEEE Transactions on Knowledge and Data Engineering
*  IEEE Transactions on Circuits and Systems for Video Technology
*  Neural Networks
*  IEEE Multimedia
*  IEEE Signal Processing Letters
*  Speech Communication
*  Neurocomputing
*  Information Fusion
*  Signal Processing
*  Applied Acoustics
*  Computer Speech&Languange
*  Biomedical Signal Processing and Control
*  INTERSPEECH 2018~2021, ICASSP 2021
...

<span id = "Students"> </span>
## **æŒ‡å¯¼å­¦ç”Ÿ**
### **åœ¨è¯»ç ”ç©¶ç”Ÿ**
2020çº§
1. [èµµå¯å¯]()ï¼Œç ”ç©¶æ–¹å‘ï¼šè·¨åŸŸè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«
2. [å§¬äº®]()ï¼Œç ”ç©¶æ–¹å‘ï¼šè·¨åŸŸäººè„¸è¡¨æƒ…è¯†åˆ«
3. [åˆ˜å‘é›¨]()ï¼Œç ”ç©¶æ–¹å‘ï¼šå¤šè§†å›¾èšç±»
4. [æç»å‡¯]()ï¼Œç ”ç©¶æ–¹å‘ï¼šè¿ç§»å­¦ä¹ ã€è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«
5. [å®‹ç´«æµ©]()ï¼Œç ”ç©¶æ–¹å‘ï¼šï¼ˆå¤šè§†å›¾ï¼‰ç‰¹å¾é€‰æ‹©

2019çº§
1. [å¼ é›¯å©§]()ï¼Œç ”ç©¶æ–¹å‘ï¼šåŸºäºè¿ç§»å­¦ä¹ çš„è·¨åŸŸäººè„¸è¡¨æƒ…è¯†åˆ« (ã€Šæ•°æ®é‡‡é›†ä¸å¤„ç†ã€‹åˆŠå‡ºä¸€ç¯‡ã€ä¸€ç¯‡è®ºæ–‡åœ¨å®¡)
2. [ç››è¶…]()ï¼Œ ç ”ç©¶æ–¹å‘ï¼šåŸºäºå›¾æ­£åˆ™çš„æ— ç›‘ç£ç‰¹å¾é€‰æ‹© (ã€Šä¿¡å·å¤„ç†ã€‹å½•ç”¨ä¸€ç¯‡ã€ä¸¤ç¯‡è®ºæ–‡åœ¨å®¡)

2018çº§
1. [é™ˆæ ‹æ¢]()ï¼Œç ”ç©¶æ–¹å‘ï¼šåŸºäºç¨€ç–è¿ç§»å­¦ä¹ çš„äººè„¸è¡¨æƒ…è¯†åˆ«. (IEICEã€DSPè®ºæ–‡å„åˆŠå‡ºä¸€ç¯‡,ä¸¤ç¯‡è®ºæ–‡åœ¨å®¡)
2. [å¼ ä¼Ÿå»º]()ï¼Œç ”ç©¶æ–¹å‘ï¼šåŸºäºå­ç©ºé—´è¿ç§»å­¦ä¹ çš„è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«. (IEEE TALSPã€TCDSè®ºæ–‡å„åˆŠå‡ºä¸€ç¯‡)

### **ä¼˜ç§€æœ¬ç§‘æ¯•ä¸šè®ºæ–‡**
1. 2019å¹´ åŸºäºæ·±å±‚å­ç©ºé—´å­¦ä¹ çš„äººè„¸è¡¨æƒ…è¯†åˆ«æ–¹æ³•ç ”ç©¶ å¼ è¿é›ª
2. 2018å¹´ åŸºäºæœºå™¨å­¦ä¹ çš„äº¤é€šå¤§æ•°æ®é¢„æµ‹   æå°šæ³½

### **å¤§å­¦ç”Ÿç§‘æŠ€åˆ›æ–°æ´»åŠ¨**
1. 2020å¹´ ç ”ç©¶ç”Ÿç§‘æŠ€åˆ›æ–°åŸºé‡‘é¡¹ç›®(é‡ç‚¹)ï¼šåŸºäºå­ç©ºé—´è¿ç§»å­¦ä¹ çš„è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ç ”ç©¶ï¼ˆå¼ ä¼Ÿå»ºï¼‰
2. 2019å¹´ â€œæ™ºæ…§å®éªŒå®¤â€çƒŸå°å¤§å­¦ç¬¬ä¸€å±Šç ”ç©¶ç”Ÿåˆ›æ–°å®è·µå¤§èµ›(ç‰¹ç­‰å¥–)ï¼š è·¨åŒºåŸŸçš„äººè„¸è¡¨æƒ…è¯†åˆ«ï¼ˆé™ˆæ ‹æ¢ã€å¼ é›¯å©§ï¼‰
3. 2017å¹´ å¤§å­¦ç”Ÿåˆ›æ–°åˆ›ä¸šè®­ç»ƒè®¡åˆ’é¡¹ç›®:â€œåŸºäºæœºå™¨å­¦ä¹ çš„åŸå¸‚äº¤é€šåŠ¨æ€é¢„æµ‹â€ ï¼ˆæå€©ã€å¼ è¿é›ªã€é©¬æ–‡é™ã€æå°šæ³½ã€è´¾å¬é£ç­‰ï¼‰
4. 2016-2019å¹´ ä¸–ç•Œå¤§å­¦ç”Ÿè¶…çº§è®¡ç®—æœºæ¯”èµ›ASCï¼ˆäºŒç­‰å¥–ï¼‰

<span id = "Resources"> </span>
## **èµ„æº**
1. [ä¸­å›½è®¡ç®—æœºå­¦ä¼šæ¨èå›½é™…å­¦æœ¯ä¼šè®®å’ŒæœŸåˆŠç›®å½•](https://www.ccf.org.cn/c/2019-04-25/663625.shtml)
2. [æ¸…åå¤§å­¦è®¡ç®—æœºå­¦ç§‘æ¨èå­¦æœ¯ä¼šè®®å’ŒæœŸåˆŠåˆ—è¡¨](https://dsc.jnu.edu.cn/56/e9/c15581a415465/page.htm)
3. [ä¸­å›½è‡ªåŠ¨åŒ–å­¦ä¼šæ¨èå­¦æœ¯æœŸåˆŠç›®å½•ï¼ˆè¯•è¡Œï¼‰](http://www.caa.org.cn/Public/FCKuploads/00.pdf)
3. [æœºå™¨å­¦ä¹ ç™½æ¿æ¨å¯¼](https://space.bilibili.com/97068901?from=search&seid=6239692258513089842)
4. [è¿ç§»å­¦ä¹ ](https://github.com/jindongwang/transferlearning)
5. [è·¨åŸŸäººè„¸è¡¨æƒ…è¯†åˆ«](https://mp.weixin.qq.com/s/vK4jHAntOvwnJ5FwHgDCVw)
5. [å¦‚ä½•åšç ”ç©¶](http://www.jdl.ac.cn/how_to_research/index1_1.htm#1)
6. [å¸ˆç”Ÿå…³ç³»å¤§æ‚çƒ©](https://frostliu.github.io/discussions)
7. [AIä¼šè®®Deadline](https://aideadlin.es/?sub=ML,CV,NLP,RO,SP,DM)


[â†‘Top](#Top)

<a href="https://info.flagcounter.com/B3Rj"><img src="https://s11.flagcounter.com/map/B3Rj/size_s/txt_000000/border_CCCCCC/pageviews_0/viewers_0/flags_0/" alt="Flag Counter" border="0"></a>

**æ›´æ–°æ—¶é—´ï¼š2021/05/01**

